#!/usr/bin/python3
# -*- coding: utf-8 -*-
import csv
import numpy as np
import matplotlib.pyplot as plt

# (a)

def load_data(filename):
    """should load the data from the given file, returning a matrix for X and a vector for y""" 
    #TODO your code here


X,y = load_data('ex_data.csv')
m = len(y)

# extend the data in order to add a bias term to the dot product with theta
X = np.column_stack([np.ones(m), X])

print(X)
print(y)


## now plot the data
#TODO your code here




# (b)
def sigmoid(x): 
    #TODO your code here



# (c)

def cost(theta):
    """compute the cost function from the parameters theta"""
    #TODO your code here

def grad(theta):
    """compute the derivative of the cost function with respect to theta""" 
    #TODO your code here


# (d)
def GD(gradf, theta0, lr, steps, costf):
    """
    Args:
      gradf: gradient of the cost function
      theta0: initail value for the parameters theta
      lr: learing rate
      steps: total number of iterations to perform
      costf: cost function (only needed for debugging/outputting intermediate results)
    returns the final value for theta
    """ 
    #TODO your code here

# (e)
# use these parameters for training the model
train = GD(grad, np.zeros(3), 1e-5, 100000, cost)


#also plot the decisicon boundary and calculate the accuracy
#TODO your code here

